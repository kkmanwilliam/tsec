{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import string\n",
    "import logging\n",
    "import requests\n",
    "import argparse\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from os import mkdir\n",
    "from os.path import isdir\n",
    "\n",
    "class Crawler():\n",
    "    def __init__(self, prefix=\"data\"):\n",
    "        ''' Make directory if not exist when initialize '''\n",
    "        if not isdir(prefix):\n",
    "            mkdir(prefix)\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def _clean_row(self, row):\n",
    "        ''' Clean comma and spaces '''\n",
    "        for index, content in enumerate(row):\n",
    "            row[index] = re.sub(\",\", \"\", content.strip())\n",
    "        return row\n",
    "\n",
    "    def _record(self, stock_id, row):\n",
    "        ''' Save row to csv file '''\n",
    "        f = open('{}/{}.csv'.format(self.prefix, stock_id), 'a')\n",
    "        cw = csv.writer(f, lineterminator='\\n')\n",
    "        cw.writerow(row)\n",
    "        f.close()\n",
    "\n",
    "    def _get_tse_data(self, date_tuple):\n",
    "        date_str = '{0}{1:02d}{2:02d}'.format(date_tuple[0], date_tuple[1], date_tuple[2])\n",
    "        url = 'http://www.twse.com.tw/exchangeReport/MI_INDEX'\n",
    "\n",
    "        query_params = {\n",
    "            'date': date_str,\n",
    "            'response': 'json',\n",
    "            'type': 'ALL',\n",
    "            '_': str(round(time.time() * 1000) - 500)\n",
    "        }\n",
    "\n",
    "        # Get json data\n",
    "        page = requests.get(url, params=query_params)\n",
    "\n",
    "        if not page.ok:\n",
    "            logging.error(\"Can not get TSE data at {}\".format(date_str))\n",
    "            return\n",
    "\n",
    "        content = page.json()\n",
    "\n",
    "        # For compatible with original data\n",
    "        date_str_mingguo = '{0}/{1:02d}/{2:02d}'.format(date_tuple[0] - 1911, date_tuple[1], date_tuple[2])\n",
    "\n",
    "        for data in content['data9']:\n",
    "            sign = '-' if data[9].find('green') > 0 else ''\n",
    "            row = self._clean_row([\n",
    "                date_str_mingguo, # 日期\n",
    "                data[2], # 成交股數\n",
    "                data[4], # 成交金額\n",
    "                data[5], # 開盤價\n",
    "                data[6], # 最高價\n",
    "                data[7], # 最低價\n",
    "                data[8], # 收盤價\n",
    "                sign + data[10], # 漲跌價差\n",
    "                data[3], # 成交筆數\n",
    "            ])\n",
    "\n",
    "            self._record(data[0].strip(), row)\n",
    "\n",
    "    def _get_otc_data(self, date_tuple):\n",
    "        date_str = '{0}/{1:02d}/{2:02d}'.format(date_tuple[0] - 1911, date_tuple[1], date_tuple[2])\n",
    "        ttime = str(int(time.time()*100))\n",
    "        url = 'http://www.tpex.org.tw/web/stock/aftertrading/daily_close_quotes/stk_quote_result.php?l=zh-tw&d={}&_={}'.format(date_str, ttime)\n",
    "        page = requests.get(url)\n",
    "\n",
    "        if not page.ok:\n",
    "            logging.error(\"Can not get OTC data at {}\".format(date_str))\n",
    "            return\n",
    "\n",
    "        result = page.json()\n",
    "\n",
    "        if result['reportDate'] != date_str:\n",
    "            logging.error(\"Get error date OTC data at {}\".format(date_str))\n",
    "            return\n",
    "\n",
    "        for table in [result['mmData'], result['aaData']]:\n",
    "            for tr in table:\n",
    "                row = self._clean_row([\n",
    "                    date_str,\n",
    "                    tr[8], # 成交股數\n",
    "                    tr[9], # 成交金額\n",
    "                    tr[4], # 開盤價\n",
    "                    tr[5], # 最高價\n",
    "                    tr[6], # 最低價\n",
    "                    tr[2], # 收盤價\n",
    "                    tr[3], # 漲跌價差\n",
    "                    tr[10] # 成交筆數\n",
    "                ])\n",
    "                self._record(tr[0], row)\n",
    "\n",
    "\n",
    "    def get_data(self, date_tuple):\n",
    "        print('Crawling {}'.format(date_tuple))\n",
    "        self._get_tse_data(date_tuple)\n",
    "        self._get_otc_data(date_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-c', '--check'], dest='check', nargs=0, const=True, default=False, type=None, choices=None, help='crawl back 10 days for check data', metavar=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isdir('log'):\n",
    "    os.makedirs('log')\n",
    "logging.basicConfig(filename='log/crawl-error.log',\n",
    "    level=logging.ERROR,\n",
    "    format='%(asctime)s\\t[%(levelname)s]\\t%(message)s',\n",
    "    datefmt='%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "# Get arguments\n",
    "parser = argparse.ArgumentParser(description='Crawl data at assigned day')\n",
    "parser.add_argument('day', type=int, nargs='*',\n",
    "    help='assigned day (format: YYYY MM DD), default is today')\n",
    "parser.add_argument('-b', '--back', action='store_true',\n",
    "    help='crawl back from assigned day until 2004/2/11')\n",
    "parser.add_argument('-c', '--check', action='store_true',\n",
    "    help='crawl back 10 days for check data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 9, 19)\n",
      "Crawling (2019, 9, 18)\n",
      "Crawling (2019, 9, 17)\n",
      "Crawling (2019, 9, 16)\n",
      "Crawling (2019, 9, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/09/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 9, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/09/14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 9, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/09/13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 9, 12)\n",
      "Crawling (2019, 9, 11)\n",
      "Crawling (2019, 9, 10)\n",
      "Crawling (2019, 9, 9)\n",
      "Crawling (2019, 9, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/09/08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 9, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/09/07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 9, 6)\n",
      "Crawling (2019, 9, 5)\n",
      "Crawling (2019, 9, 4)\n",
      "Crawling (2019, 9, 3)\n",
      "Crawling (2019, 9, 2)\n",
      "Crawling (2019, 9, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/09/01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 30)\n",
      "Crawling (2019, 8, 29)\n",
      "Crawling (2019, 8, 28)\n",
      "Crawling (2019, 8, 27)\n",
      "Crawling (2019, 8, 26)\n",
      "Crawling (2019, 8, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 23)\n",
      "Crawling (2019, 8, 22)\n",
      "Crawling (2019, 8, 21)\n",
      "Crawling (2019, 8, 20)\n",
      "Crawling (2019, 8, 19)\n",
      "Crawling (2019, 8, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 16)\n",
      "Crawling (2019, 8, 15)\n",
      "Crawling (2019, 8, 14)\n",
      "Crawling (2019, 8, 13)\n",
      "Crawling (2019, 8, 12)\n",
      "Crawling (2019, 8, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 8)\n",
      "Crawling (2019, 8, 7)\n",
      "Crawling (2019, 8, 6)\n",
      "Crawling (2019, 8, 5)\n",
      "Crawling (2019, 8, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/08/03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 8, 2)\n",
      "Crawling (2019, 8, 1)\n",
      "Crawling (2019, 7, 31)\n",
      "Crawling (2019, 7, 30)\n",
      "Crawling (2019, 7, 29)\n",
      "Crawling (2019, 7, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/07/28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 7, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/07/27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 7, 26)\n",
      "Crawling (2019, 7, 25)\n",
      "Crawling (2019, 7, 24)\n",
      "Crawling (2019, 7, 23)\n",
      "Crawling (2019, 7, 22)\n",
      "Crawling (2019, 7, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/07/21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 7, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/07/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 7, 19)\n",
      "Crawling (2019, 7, 18)\n",
      "Crawling (2019, 7, 17)\n",
      "Crawling (2019, 7, 16)\n",
      "Crawling (2019, 7, 15)\n",
      "Crawling (2019, 7, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/07/14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 7, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/07/13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 7, 12)\n",
      "Crawling (2019, 7, 11)\n",
      "Crawling (2019, 7, 10)\n",
      "Crawling (2019, 7, 9)\n",
      "Crawling (2019, 7, 8)\n",
      "Crawling (2019, 7, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/07/07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 7, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/07/06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 7, 5)\n",
      "Crawling (2019, 7, 4)\n",
      "Crawling (2019, 7, 3)\n",
      "Crawling (2019, 7, 2)\n",
      "Crawling (2019, 7, 1)\n",
      "Crawling (2019, 6, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 28)\n",
      "Crawling (2019, 6, 27)\n",
      "Crawling (2019, 6, 26)\n",
      "Crawling (2019, 6, 25)\n",
      "Crawling (2019, 6, 24)\n",
      "Crawling (2019, 6, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 21)\n",
      "Crawling (2019, 6, 20)\n",
      "Crawling (2019, 6, 19)\n",
      "Crawling (2019, 6, 18)\n",
      "Crawling (2019, 6, 17)\n",
      "Crawling (2019, 6, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 14)\n",
      "Crawling (2019, 6, 13)\n",
      "Crawling (2019, 6, 12)\n",
      "Crawling (2019, 6, 11)\n",
      "Crawling (2019, 6, 10)\n",
      "Crawling (2019, 6, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 6)\n",
      "Crawling (2019, 6, 5)\n",
      "Crawling (2019, 6, 4)\n",
      "Crawling (2019, 6, 3)\n",
      "Crawling (2019, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 6, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/06/01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 5, 31)\n",
      "Crawling (2019, 5, 30)\n",
      "Crawling (2019, 5, 29)\n",
      "Crawling (2019, 5, 28)\n",
      "Crawling (2019, 5, 27)\n",
      "Crawling (2019, 5, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/05/26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 5, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/05/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 5, 24)\n",
      "Crawling (2019, 5, 23)\n",
      "Crawling (2019, 5, 22)\n",
      "Crawling (2019, 5, 21)\n",
      "Crawling (2019, 5, 20)\n",
      "Crawling (2019, 5, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/05/19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 5, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/05/18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 5, 17)\n",
      "Crawling (2019, 5, 16)\n",
      "Crawling (2019, 5, 15)\n",
      "Crawling (2019, 5, 14)\n",
      "Crawling (2019, 5, 13)\n",
      "Crawling (2019, 5, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/05/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 5, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/05/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 5, 10)\n",
      "Crawling (2019, 5, 9)\n",
      "Crawling (2019, 5, 8)\n",
      "Crawling (2019, 5, 7)\n",
      "Crawling (2019, 5, 6)\n",
      "Crawling (2019, 5, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/05/05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 5, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/05/04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 5, 3)\n",
      "Crawling (2019, 5, 2)\n",
      "Crawling (2019, 5, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/05/01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 30)\n",
      "Crawling (2019, 4, 29)\n",
      "Crawling (2019, 4, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 26)\n",
      "Crawling (2019, 4, 25)\n",
      "Crawling (2019, 4, 24)\n",
      "Crawling (2019, 4, 23)\n",
      "Crawling (2019, 4, 22)\n",
      "Crawling (2019, 4, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 19)\n",
      "Crawling (2019, 4, 18)\n",
      "Crawling (2019, 4, 17)\n",
      "Crawling (2019, 4, 16)\n",
      "Crawling (2019, 4, 15)\n",
      "Crawling (2019, 4, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 12)\n",
      "Crawling (2019, 4, 11)\n",
      "Crawling (2019, 4, 10)\n",
      "Crawling (2019, 4, 9)\n",
      "Crawling (2019, 4, 8)\n",
      "Crawling (2019, 4, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/04/04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 4, 3)\n",
      "Crawling (2019, 4, 2)\n",
      "Crawling (2019, 4, 1)\n",
      "Crawling (2019, 3, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 29)\n",
      "Crawling (2019, 3, 28)\n",
      "Crawling (2019, 3, 27)\n",
      "Crawling (2019, 3, 26)\n",
      "Crawling (2019, 3, 25)\n",
      "Crawling (2019, 3, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 22)\n",
      "Crawling (2019, 3, 21)\n",
      "Crawling (2019, 3, 20)\n",
      "Crawling (2019, 3, 19)\n",
      "Crawling (2019, 3, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 15)\n",
      "Crawling (2019, 3, 14)\n",
      "Crawling (2019, 3, 13)\n",
      "Crawling (2019, 3, 12)\n",
      "Crawling (2019, 3, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 10)\n",
      "Crawling (2019, 3, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 8)\n",
      "Crawling (2019, 3, 7)\n",
      "Crawling (2019, 3, 6)\n",
      "Crawling (2019, 3, 5)\n",
      "Crawling (2019, 3, 4)\n",
      "Crawling (2019, 3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 3, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/03/01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 27)\n",
      "Crawling (2019, 2, 26)\n",
      "Crawling (2019, 2, 25)\n",
      "Crawling (2019, 2, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 22)\n",
      "Crawling (2019, 2, 21)\n",
      "Crawling (2019, 2, 20)\n",
      "Crawling (2019, 2, 19)\n",
      "Crawling (2019, 2, 18)\n",
      "Crawling (2019, 2, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 15)\n",
      "Crawling (2019, 2, 14)\n",
      "Crawling (2019, 2, 13)\n",
      "Crawling (2019, 2, 12)\n",
      "Crawling (2019, 2, 11)\n",
      "Crawling (2019, 2, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling (2019, 2, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Crawl raise error 2019/02/06\n"
     ]
    }
   ],
   "source": [
    "first_day = datetime.today()\n",
    "last_day = datetime(2004, 2, 11)\n",
    "crawler = Crawler()\n",
    "max_error = 5\n",
    "error_times = 0\n",
    "while error_times < max_error and first_day >= last_day:\n",
    "    try:\n",
    "        crawler.get_data((first_day.year, first_day.month, first_day.day))\n",
    "        error_times = 0\n",
    "    except:\n",
    "        date_str = first_day.strftime('%Y/%m/%d')\n",
    "        logging.error('Crawl raise error {}'.format(date_str))\n",
    "        error_times += 1\n",
    "        continue\n",
    "    finally:\n",
    "        first_day -= timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "FOLDER = 'data'\n",
    "file_name = \"9110.csv\"\n",
    "dict_rows = {}\n",
    "\n",
    "# Load and remove duplicates (use newer)\n",
    "with open('{}/{}'.format(FOLDER, file_name), 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        dict_rows[line.split(',', 1)[0]] = line\n",
    "\n",
    "dict_rows['108/02/11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 22:48:38.671892</td>\n",
       "      <td>2019-09-20 22:48:38.649677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-20 22:48:38.680364</td>\n",
       "      <td>2019-09-19 22:48:38.649677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-20 22:50:19.173628</td>\n",
       "      <td>2019-09-20 22:50:19.158241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-20 22:50:19.208995</td>\n",
       "      <td>2019-09-19 22:50:19.158241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-20 22:51:58.447923</td>\n",
       "      <td>2019-09-20 22:51:58.429583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-09-20 22:51:58.452620</td>\n",
       "      <td>2019-09-19 22:51:58.429583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-09-20 22:57:25.262022</td>\n",
       "      <td>09/20/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-09-20 22:57:25.274807</td>\n",
       "      <td>09/19/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-09-20 22:57:25.294799</td>\n",
       "      <td>09/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-09-20 22:57:25.321998</td>\n",
       "      <td>09/17/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-09-20 22:57:25.328013</td>\n",
       "      <td>09/16/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-09-20 22:57:25.338884</td>\n",
       "      <td>09/15/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-09-20 22:57:49.171514</td>\n",
       "      <td>09/20/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-09-20 22:57:49.247381</td>\n",
       "      <td>09/19/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-09-20 22:57:49.255003</td>\n",
       "      <td>09/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-09-20 22:57:49.260080</td>\n",
       "      <td>09/17/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-09-20 22:57:49.268298</td>\n",
       "      <td>09/16/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-09-20 22:57:49.284590</td>\n",
       "      <td>09/15/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Created_at                        Date\n",
       "0   2019-09-20 22:48:38.671892  2019-09-20 22:48:38.649677\n",
       "1   2019-09-20 22:48:38.680364  2019-09-19 22:48:38.649677\n",
       "2   2019-09-20 22:50:19.173628  2019-09-20 22:50:19.158241\n",
       "3   2019-09-20 22:50:19.208995  2019-09-19 22:50:19.158241\n",
       "4   2019-09-20 22:51:58.447923  2019-09-20 22:51:58.429583\n",
       "5   2019-09-20 22:51:58.452620  2019-09-19 22:51:58.429583\n",
       "6   2019-09-20 22:57:25.262022                  09/20/2019\n",
       "7   2019-09-20 22:57:25.274807                  09/19/2019\n",
       "8   2019-09-20 22:57:25.294799                  09/18/2019\n",
       "9   2019-09-20 22:57:25.321998                  09/17/2019\n",
       "10  2019-09-20 22:57:25.328013                  09/16/2019\n",
       "11  2019-09-20 22:57:25.338884                  09/15/2019\n",
       "12  2019-09-20 22:57:49.171514                  09/20/2019\n",
       "13  2019-09-20 22:57:49.247381                  09/19/2019\n",
       "14  2019-09-20 22:57:49.255003                  09/18/2019\n",
       "15  2019-09-20 22:57:49.260080                  09/17/2019\n",
       "16  2019-09-20 22:57:49.268298                  09/16/2019\n",
       "17  2019-09-20 22:57:49.284590                  09/15/2019"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "duration_covered = pd.read_csv('duration_coverage.csv') \n",
    "duration_covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 22:33:41.528149</td>\n",
       "      <td>2019-09-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 22:33:41.540542</td>\n",
       "      <td>2019-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 22:33:41.543926</td>\n",
       "      <td>2019-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 22:33:41.548543</td>\n",
       "      <td>2019-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 22:33:41.551943</td>\n",
       "      <td>2019-09-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Created_at       Date\n",
       "0 2019-09-20 22:33:41.528149 2019-09-20\n",
       "0 2019-09-20 22:33:41.540542 2019-09-19\n",
       "0 2019-09-20 22:33:41.543926 2019-09-18\n",
       "0 2019-09-20 22:33:41.548543 2019-09-17\n",
       "0 2019-09-20 22:33:41.551943 2019-09-16"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/20/2019\n",
      "09/19/2019\n",
      "09/18/2019\n",
      "09/17/2019\n",
      "09/16/2019\n",
      "09/15/2019\n",
      "09/14/2019\n",
      "09/13/2019\n",
      "09/12/2019\n",
      "09/11/2019\n"
     ]
    }
   ],
   "source": [
    "max_error = 5\n",
    "error_times = 0\n",
    "first_day = datetime(2019, 9, 20)\n",
    "last_day = datetime(2019, 9, 11)\n",
    "\n",
    "while error_times < max_error and first_day >= last_day and str(first_day.strftime(\"%m/%d/%Y\")) not in duration_covered['Date']:\n",
    "    print(first_day.strftime(\"%m/%d/%Y\"))\n",
    "    #duration_covered = duration_covered.append(pd.DataFrame({'Date':[first_day], 'Created_at':[datetime.now()]}), sort=True)\n",
    "    first_day -= timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "first_day = datetime(2019, 9, 20)\n",
    "handling_date = str(first_day.strftime(\"%m/%d/%Y\"))\n",
    "existed_day = duration_covered['Date'].tolist()\n",
    "if handling_date in existed_day:\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print(\"No\")\n",
    "    print(first_day.strftime(\"%m/%d/%Y\"))\n",
    "    print(\"====\")\n",
    "    print(duration_covered['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-09-20 22:48:38.649677',\n",
       " '2019-09-19 22:48:38.649677',\n",
       " '2019-09-20 22:50:19.158241',\n",
       " '2019-09-19 22:50:19.158241',\n",
       " '2019-09-20 22:51:58.429583',\n",
       " '2019-09-19 22:51:58.429583',\n",
       " '09/20/2019',\n",
       " '09/19/2019',\n",
       " '09/18/2019',\n",
       " '09/17/2019',\n",
       " '09/16/2019',\n",
       " '09/15/2019',\n",
       " '09/20/2019',\n",
       " '09/19/2019',\n",
       " '09/18/2019',\n",
       " '09/17/2019',\n",
       " '09/16/2019',\n",
       " '09/15/2019']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_covered['Date'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
